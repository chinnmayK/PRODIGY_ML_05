{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is enabled\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd c:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls food-101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head meta/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head meta/classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 17\n",
    "cols = 6\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(25,25))\n",
    "fig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=24) # Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\n",
    "data_dir = \"images/\"\n",
    "foods_sorted = sorted(os.listdir(data_dir))\n",
    "food_id = 0\n",
    "for i in range(rows):\n",
    "  for j in range(cols):\n",
    "    try:\n",
    "      food_selected = foods_sorted[food_id] \n",
    "      food_id += 1\n",
    "    except:\n",
    "      break\n",
    "    if food_selected == '.DS_Store':\n",
    "        continue\n",
    "    food_selected_images = os.listdir(os.path.join(data_dir,food_selected)) # returns the list of all files present in each food category\n",
    "    food_selected_random = np.random.choice(food_selected_images) # picks one food item from the list as choice, takes a list and returns one random item\n",
    "    img = plt.imread(os.path.join(data_dir,food_selected, food_selected_random))\n",
    "    ax[i][j].imshow(img)\n",
    "    ax[i][j].set_title(food_selected, pad = 10)\n",
    "    \n",
    "plt.setp(ax, xticks=[],yticks=[])\n",
    "plt.tight_layout()\n",
    "# https://matplotlib.org/users/tight_layout_guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to split dataset into train and test folders\n",
    "def prepare_data(filepath, src, dest):\n",
    "    classes_images = defaultdict(list)\n",
    "\n",
    "    # Reading the file paths from the provided text file\n",
    "    with open(filepath, 'r') as txt:\n",
    "        paths = [read.strip() for read in txt.readlines()]\n",
    "        for p in paths:\n",
    "            food = p.split('/')\n",
    "            if len(food) == 2:  # Ensure there's a valid path structure\n",
    "                classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "    # Copying the images from source to destination\n",
    "    for food in classes_images.keys():\n",
    "        print(f\"\\nCopying images into {food}\")\n",
    "        \n",
    "        food_dest_path = os.path.join(dest, food)\n",
    "        \n",
    "        if not os.path.exists(food_dest_path):\n",
    "            os.makedirs(food_dest_path)\n",
    "            \n",
    "        for img_name in classes_images[food]:\n",
    "            src_image_path = os.path.join(src, food, img_name)\n",
    "            dest_image_path = os.path.join(food_dest_path, img_name)\n",
    "            \n",
    "            if os.path.exists(src_image_path):  # Check if source image exists\n",
    "                copy(src_image_path, dest_image_path)\n",
    "            else:\n",
    "                print(f\"Warning: {src_image_path} does not exist.\")\n",
    "                \n",
    "    print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
    "import os\n",
    "\n",
    "# Change the working directory to the root if necessary\n",
    "%cd /\n",
    "\n",
    "print(\"Creating train data...\")\n",
    "\n",
    "# Adjusted the paths for the source and destination\n",
    "train_txt_path = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\meta\\train.txt'  # Raw string for file path\n",
    "images_src_path = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\images'  # Raw string for source path\n",
    "train_dest_path = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\train'  # Raw string for destination path\n",
    "\n",
    "# Calling the helper function to copy the data\n",
    "prepare_data(train_txt_path, images_src_path, train_dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
    "import os\n",
    "\n",
    "print(\"Creating test data...\")\n",
    "\n",
    "# Adjust the paths for the source and destination\n",
    "test_txt_path = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\meta\\test.txt'  # Path to test.txt\n",
    "images_src_path = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\images'  # Source path where images are stored\n",
    "test_dest_path = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\test'  # Destination path where test images will be copied\n",
    "\n",
    "# Calling the helper function to copy the test data\n",
    "prepare_data(test_txt_path, images_src_path, test_dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the train folder\n",
    "train_dir = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\train'\n",
    "\n",
    "# Count the total number of files in the train directory and its subdirectories\n",
    "total_files = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
    "\n",
    "print(f\"Total number of samples in the train folder: {total_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the test folder\n",
    "test_dir = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\test'\n",
    "\n",
    "# Count the total number of files in the test directory and its subdirectories\n",
    "total_files = sum([len(files) for r, d, files in os.walk(test_dir)])\n",
    "\n",
    "print(f\"Total number of samples in the test folder: {total_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change the working directory to C: root in Windows\n",
    "os.chdir('C:\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all 101 types of foods(sorted alphabetically)\n",
    "del foods_sorted[0] # remove .DS_Store from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copytree, rmtree\n",
    "\n",
    "# Helper method to create train_mini and test_mini data samples\n",
    "def dataset_mini(food_list, src, dest):\n",
    "    # Remove existing mini dataset if it already exists\n",
    "    if os.path.exists(dest):\n",
    "        rmtree(dest)  # Remove the destination directory\n",
    "        print(f\"Removed existing directory: {dest}\")\n",
    "    \n",
    "    # Create the destination directory\n",
    "    os.makedirs(dest)\n",
    "    print(f\"Created new directory: {dest}\")\n",
    "    \n",
    "    # Copy selected food categories to the mini dataset\n",
    "    for food_item in food_list:\n",
    "        src_path = os.path.join(src, food_item)\n",
    "        dest_path = os.path.join(dest, food_item)\n",
    "        \n",
    "        # Ensure the source food category exists before copying\n",
    "        if os.path.exists(src_path):\n",
    "            print(f\"Copying images from {src_path} to {dest_path}\")\n",
    "            copytree(src_path, dest_path)\n",
    "        else:\n",
    "            print(f\"Warning: {src_path} does not exist.\")\n",
    "            \n",
    "    print(\"Copying Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the source and destination paths for train and test mini datasets\n",
    "food_list = ['apple_pie', 'pizza', 'omelette']\n",
    "\n",
    "# Source paths for train and test datasets\n",
    "src_train = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\train'\n",
    "src_test = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\test'\n",
    "\n",
    "# Destination paths for the mini train and test datasets\n",
    "dest_train = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\train_mini'\n",
    "dest_test = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\test_mini'\n",
    "\n",
    "# Create the mini train dataset\n",
    "print(\"Creating train mini dataset...\")\n",
    "dataset_mini(food_list, src_train, dest_train)\n",
    "\n",
    "# Create the mini test dataset\n",
    "print(\"Creating test mini dataset...\")\n",
    "dataset_mini(food_list, src_test, dest_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the food items to include in the mini dataset\n",
    "food_list = ['apple_pie', 'pizza', 'omelette']\n",
    "\n",
    "# Source path for the original train dataset\n",
    "src_train = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\train'\n",
    "\n",
    "# Destination path for the mini train dataset\n",
    "dest_train = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\train_mini'\n",
    "\n",
    "# Create the mini train dataset\n",
    "print(\"Creating train data folder with new classes...\")\n",
    "dataset_mini(food_list, src_train, dest_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the train_mini folder\n",
    "train_mini_dir = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\train_mini'\n",
    "\n",
    "# Count the total number of files in the train_mini directory and its subdirectories\n",
    "total_samples = sum([len(files) for r, d, files in os.walk(train_mini_dir)])\n",
    "\n",
    "print(f\"Total number of samples in train folder: {total_samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the food items to include in the mini dataset\n",
    "food_list = ['apple_pie', 'pizza', 'omelette']\n",
    "\n",
    "# Source path for the original test dataset\n",
    "src_test = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\test'\n",
    "\n",
    "# Destination path for the mini test dataset\n",
    "dest_test = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\test_mini'\n",
    "\n",
    "# Create the mini test dataset\n",
    "print(\"Creating test data folder with new classes...\")\n",
    "dataset_mini(food_list, src_test, dest_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the test_mini folder\n",
    "test_mini_dir = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\test_mini'\n",
    "\n",
    "# Count the total number of files in the test_mini directory and its subdirectories\n",
    "total_samples_test = sum([len(files) for r, d, files in os.walk(test_mini_dir)])\n",
    "\n",
    "print(f\"Total number of samples in test folder: {total_samples_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Clear previous session\n",
    "K.clear_session()\n",
    "\n",
    "# Parameters\n",
    "n_classes = 3\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\train_mini'\n",
    "validation_data_dir = r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\test_mini'\n",
    "nb_train_samples = 2250\n",
    "nb_validation_samples = 750\n",
    "batch_size = 16\n",
    "\n",
    "# Data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Load the ResNet50 model\n",
    "resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "x = resnet50.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Final prediction layer\n",
    "predictions = Dense(n_classes, kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=resnet50.input, outputs=predictions)\n",
    "model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "# Callbacks\n",
    "checkpointer = ModelCheckpoint(filepath=r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\best_model_3class.keras', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger(r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\history_3class.log')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    "    callbacks=[csv_logger, checkpointer]\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\model_trained_3class.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the class-to-index mapping\n",
    "class_map_3 = train_generator.class_indices\n",
    "print(class_map_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracy(history, title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='validation_accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history, title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='validation_loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy\n",
    "plot_accuracy(history, 'FOOD101-ResNet50')\n",
    "\n",
    "# Plotting loss\n",
    "plot_loss(history, 'FOOD101-ResNet50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = load_model(r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\best_model_3class.keras', compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Ensure this directory exists\n",
    "download_directory = r\"C:\\Users\\chinn\\Downloads\"  # Change this path as needed\n",
    "os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "def download_image(url, filename):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "        full_path = os.path.join(download_directory, filename)\n",
    "        with open(full_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded: {full_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {filename}: {e}\")\n",
    "\n",
    "# URLs of the images (Updated with valid links)\n",
    "download_image(\"https://queen.com.au/wp-content/uploads/2019/10/Pastel-Rainbow-Cupcakes-WEB.jpg\", \"cupcakes.jpg\")\n",
    "download_image(\"https://www.sidechef.com/recipe/b75f5913-ca28-41a7-b985-30ab40045d7a.jpg\", \"springrolls_new.jpg\")  # Changed filename\n",
    "download_image(\"https://i0.wp.com/www.amysrecipebook.com/wp-content/uploads/2021/01/pepperonipizza-8-web.jpg\", \"pizza.jpg\")  # Valid pizza URL\n",
    "download_image(\"https://c1.staticflickr.com/1/84/262952165_7ba3466108_z.jpg\", \"garlicbread.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load the trained model\n",
    "model_best = load_model(r'C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\best_model_3class.keras', compile=False)\n",
    "\n",
    "# Function to preprocess images and make predictions\n",
    "def predict_class(model, image_paths, show_images=False):\n",
    "    class_map = {0: 'Class_1', 1: 'Class_2', 2: 'Class_3'}  # Update with your actual class names\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        # Load and preprocess the image\n",
    "        img = load_img(image_path, target_size=(224, 224))  # Resize to the input shape of your model\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "        img_array /= 255.0  # Normalize pixel values\n",
    "\n",
    "        # Make prediction\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class = np.argmax(predictions)\n",
    "\n",
    "        # Output the result\n",
    "        print(f\"Predicted class for {image_path}: {class_map[predicted_class]}\")\n",
    "\n",
    "        # Optionally display the image\n",
    "        if show_images:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            plt.imshow(img_array[0])  # Display the image\n",
    "            plt.title(f\"Predicted: {class_map[predicted_class]}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "# List of images to test\n",
    "images = [\n",
    "    r'C:\\Users\\chinn\\Downloads\\cupcakes.jpg',\n",
    "    r'C:\\Users\\chinn\\Downloads\\springrolls_new.jpg',\n",
    "    r'C:\\Users\\chinn\\Downloads\\pizza.jpg',\n",
    "    r'C:\\Users\\chinn\\Downloads\\garlicbread.jpg'\n",
    "]\n",
    "\n",
    "# Call the function to predict classes\n",
    "predict_class(model_best, images, show_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(r\"C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_plot_path = r\"C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\model_plot.png\"\n",
    "tf.keras.utils.plot_model(model, to_file=model_plot_path, show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_summary(model):\n",
    "    # Get model summary\n",
    "    summary_str = []\n",
    "    model.summary(print_fn=lambda x: summary_str.append(x))\n",
    "\n",
    "    # Debugging: print the summary lines\n",
    "    print(\"Model Summary Lines:\")\n",
    "    for line in summary_str:\n",
    "        print(line)\n",
    "\n",
    "    # Prepare data for the table\n",
    "    table_data = []\n",
    "    for line in summary_str[2:]:  # Skip the first two lines (header and separators)\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 3:\n",
    "            layer_info = parts[:3]  # Take the first three parts (Layer, Output Shape, Param #)\n",
    "            table_data.append(layer_info)\n",
    "        else:\n",
    "            print(f\"Unexpected line format: {line}\")  # Debugging unexpected formats\n",
    "\n",
    "    # Check if table_data is empty\n",
    "    if not table_data:\n",
    "        print(\"No data found for the table. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, len(table_data) * 0.5 + 1))  # Adjust height based on rows\n",
    "\n",
    "    # Create a table to display model summary\n",
    "    table = ax.table(cellText=table_data,\n",
    "                     colLabels=[\"Layer (type)\", \"Output Shape\", \"Param #\"],\n",
    "                     loc='center', cellLoc='center')\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.5, 1.5)  # Scale table size\n",
    "    ax.axis('off')  # Hide axes\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plt.savefig(r\"C:\\Users\\chinn\\ml\\PRODIGY_ML_05\\PRODIGY_ML_05\\food-101\\model_summary.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot model summary\n",
    "plot_model_summary(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
